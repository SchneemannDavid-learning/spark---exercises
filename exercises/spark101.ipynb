{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe\n",
    "\n",
    "2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "- Create 1 column of output that contains a message like the one below:\n",
    "- Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker.\n",
    "\n",
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/13 08:18:36 WARN Utils: Your hostname, Davids-MacBook-Pro-3.local resolves to a loopback address: 127.0.0.1; using 192.168.7.20 instead (on interface en0)\n",
      "22/09/13 08:18:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/13 08:18:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Install\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark.range(5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/13 08:18:49 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Creating a Spark Object\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A. Create dataframe of languages with 1 column named language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.DataFrame({\n",
    "    \"language\": [\"r\", \"python\", \"sql\", \"julia\", \"scala\", \"php\", \"html\", \"css\", \"javascript\"]\n",
    "})\n",
    "df = spark.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> B. View the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C. The shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  9  x  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame shape: \", df.count(), \" x \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> D. The first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(language='r'),\n",
       " Row(language='python'),\n",
       " Row(language='sql'),\n",
       " Row(language='julia'),\n",
       " Row(language='scala')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the mpg dataset as a spark dataframe.  \n",
    "\n",
    "    > A. Create 1 column of output that contains a message like the following for each vehicle: *The 1999 audi a4 has a 4 cylinder engine.*  \n",
    "    > B. Transform the trans column so that it only contains either manual or auto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pydataset\n",
    "\n",
    "mpg = spark.createDataFrame(pydataset.data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A. Create 1 column of output that contains a message like the following for each vehicle: *The 1999 audi a4 has a 4 cylinder engine.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f4/zvhcnx4s015b5glz2c1q5hth0000gn/T/ipykernel_2930/1451132700.py:2: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  pd.concat(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mpg\u001b[39m.\u001b[39mselect(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     pd\u001b[39m.\u001b[39;49mconcat(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         lit(\u001b[39m\"\u001b[39;49m\u001b[39mThe \u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         col(\u001b[39m\"\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         lit(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         col(\u001b[39m\"\u001b[39;49m\u001b[39mmanufacturer\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         lit(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         col(\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         lit(\u001b[39m\"\u001b[39;49m\u001b[39m has a \u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         col(\u001b[39m\"\u001b[39;49m\u001b[39mcyl\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         lit(\u001b[39m\"\u001b[39;49m\u001b[39m cylinder engine.\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mvehicle_cylinder_desc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidschneemann/codeup/spark---exercises/exercises/spark101.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\u001b[39m.\u001b[39mshow(truncate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    348\u001b[0m         objs,\n\u001b[1;32m    349\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    350\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    351\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    352\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    353\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    354\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    355\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    356\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    357\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    369\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    370\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m ):\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(objs, (ABCSeries, ABCDataFrame, \u001b[39mstr\u001b[39;49m)):\n\u001b[1;32m    382\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfirst argument must be an iterable of pandas \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobjects, you passed an object of type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(objs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    385\u001b[0m         )\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m join \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/generic.py:45\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m@classmethod\u001b[39m  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check\u001b[39m(\u001b[39mcls\u001b[39m, inst) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(inst, attr, \u001b[39m\"\u001b[39;49m\u001b[39m_typ\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39min\u001b[39;49;00m comp\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/sql/column.py:1044\u001b[0m, in \u001b[0;36mColumn.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1044\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1045\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert column into bool: please use \u001b[39m\u001b[39m'\u001b[39m\u001b[39m&\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m'\u001b[39m\u001b[39mand\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m'\u001b[39m\u001b[39mor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m~\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot\u001b[39m\u001b[39m'\u001b[39m\u001b[39m when building DataFrame boolean expressions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    pd.concat(\n",
    "        lit(\"The \"),\n",
    "        col(\"year\"),\n",
    "        lit(\" \"),\n",
    "        col(\"manufacturer\"),\n",
    "        lit(\" \"),\n",
    "        col(\"model\"),\n",
    "        lit(\" has a \"),\n",
    "        col(\"cyl\"),\n",
    "        lit(\" cylinder engine.\"),\n",
    "    ).alias(\"vehicle_cylinder_desc\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> B. Transform the trans column so that it only contains either manual or auto. This can be done in many ways. We will demonstrate it using regexp_extract, regexp_replace, and when. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|        a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|        a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|        a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-----------+\n",
      "|     trans|regexp_extract|regexp_replace|when + like|\n",
      "+----------+--------------+--------------+-----------+\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "+----------+--------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiple ways to do this, here's 3 of them\n",
    "mpg.select(\n",
    "    'trans',\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\\(\", 1).alias(\"regexp_extract\"),\n",
    "    regexp_replace(\"trans\", r\"\\(.+$\", \"\").alias(\"regexp_replace\"),\n",
    "    when(\n",
    "        mpg.trans.like(\"auto%\"), \"auto\"\n",
    "    ).otherwise(\"manual\").alias(\"when + like\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>year</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drv</th>\n",
       "      <th>cty</th>\n",
       "      <th>hwy</th>\n",
       "      <th>fl</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m5)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m6)</td>\n",
       "      <td>f</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(av)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(s6)</td>\n",
       "      <td>f</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m6)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>manual(m5)</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(s6)</td>\n",
       "      <td>f</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n",
       "0           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n",
       "1           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n",
       "2           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n",
       "3           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n",
       "4           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n",
       "..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n",
       "229   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n",
       "230   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n",
       "231   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n",
       "232   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n",
       "233   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n",
       "\n",
       "       class  \n",
       "0    compact  \n",
       "1    compact  \n",
       "2    compact  \n",
       "3    compact  \n",
       "4    compact  \n",
       "..       ...  \n",
       "229  midsize  \n",
       "230  midsize  \n",
       "231  midsize  \n",
       "232  midsize  \n",
       "233  midsize  \n",
       "\n",
       "[234 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpg.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    > A. What percentage of observations are smokers?  \n",
    "    > B. Create a column that contains the tip percentage  \n",
    "    > C. Calculate the average tip percentage for each combination of sex and smoker.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tips dataset\n",
    "\n",
    "tips = spark.createDataFrame(pydataset.data(\"tips\"))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A. What percentage of observations are smokers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 15:>                                                       (0 + 10) / 10]\r\n",
      "\r\n",
      "[Stage 15:==================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|smoker|count|            percent|\n",
      "+------+-----+-------------------+\n",
      "|    No|  151| 0.6188524590163934|\n",
      "|   Yes|   93|0.38114754098360654|\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupby('smoker').count().withColumn('percent', col('count') / tips.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|    62%|\n",
      "|   Yes|   93|    38%|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().withColumn(\n",
    "    \"percent\",\n",
    "    concat(round((col(\"count\") / tips.count() * 100), 0).cast(\"int\"), lit(\"%\")),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill')).show()\n",
    "\n",
    "tips.withColumn(\"tip_percentage\", expr('tip / total_bill')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|   sex|    No|   Yes|\n",
      "+------+------+------+\n",
      "|Female|0.1569|0.1822|\n",
      "|  Male|0.1607|0.1528|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# method chaining - df.method1().method2()....\n",
    "(\n",
    "    tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill'))\n",
    "    .groupby(\"sex\")\n",
    "    .pivot(\"smoker\") # make a pivot table\n",
    "    .agg(round(mean(\"tip_percentage\"), 4))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|   sex|    No|   Yes|\n",
      "+------+------+------+\n",
      "|Female|0.1569|0.1822|\n",
      "|  Male|0.1607|0.1528|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternate syntax with backslashes\n",
    "tips.withColumn(\"tip_percentage\", col('tip') / col('total_bill'))\\\n",
    "    .groupby(\"sex\")\\\n",
    "    .pivot(\"smoker\")\\\n",
    "    .agg(round(mean(\"tip_percentage\"), 4))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.  \n",
    "\n",
    "    > A. Convert the temperatures to farenheight.  \n",
    "    > B. Which month has the most rain, on average?  \n",
    "    > C. Which year was the windiest?  \n",
    "    > D. What is the most frequent type of weather in January?  \n",
    "    > E. What is the average high and low tempurature on sunny days in July in 2013 and 2014?  \n",
    "    > F. What percentage of days were rainy in q3 of 2015?  \n",
    "    > G. For each year, find what percentage of days it rained (had non-zero precipitation).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather()\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A. Convert temperatures from c to f:  (0°C × 9/5) + 32 = 32°F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather()\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather = weather.withColumn(\n",
    "    \"temp_max\", (col(\"temp_max\") * 9 / 5 + 32)\n",
    ").withColumn(\"temp_min\", (col(\"temp_min\") * 9 / 5 + 32))\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------------------+--------------------+----+-------+\n",
      "|               date|precipitation|            temp_max|            temp_min|wind|weather|\n",
      "+-------------------+-------------+--------------------+--------------------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|2.1808622660113093E7| 1.858688840350548E7| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|2.0899928382608384E7| 1.767819412600077E7| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|2.1354275521360748E7|1.9495582681010194E7| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|2.1560796948066354E7|1.8834714115552224E7| 4.7|   rain|\n",
      "+-------------------+-------------+--------------------+--------------------+----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> B. Which month has the most rain, on average? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = (\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(sum(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C. Which year is the windiest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2012, total_winds=1244.7),\n",
       " Row(year=2014, total_winds=1236.5),\n",
       " Row(year=2015, total_winds=1153.2999999999997),\n",
       " Row(year=2013, total_winds=1100.8000000000002)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_winds\"))\n",
    "    .sort(col(\"total_winds\").desc())\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> D. What is the most frequent type of weather in january? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(col(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 143:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|drizzle|   54|\n",
      "|   rain|  259|\n",
      "|    sun|  714|\n",
      "|   snow|   23|\n",
      "|    fog|  411|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# .value_counts for spark\n",
    "weather.groupBy('weather').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> E. What is the average high and low tempurature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|average_high_temp| average_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> F. What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in pandas -- (df.weather == \"rain\").mean()\n",
    "# measure a rainy day by weather == rain\n",
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> G.  For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 153:=====>                                                  (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|      avg(did_rain)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# measure a rainy day by precipitation > 0\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"did_rain\"), \"year\")\n",
    "    .groupby(\"year\")\n",
    "    .agg(mean(\"did_rain\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
